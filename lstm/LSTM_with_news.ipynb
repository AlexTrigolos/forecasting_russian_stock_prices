{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NAMhr2mHVvZ",
        "outputId": "a4810ef6-472e-408b-ce33-34a1a291eecb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.11/dist-packages (1.38.16)\n",
            "Requirement already satisfied: botocore<1.39.0,>=1.38.16 in /usr/local/lib/python3.11/dist-packages (from boto3) (1.38.16)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.13.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from boto3) (0.12.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore<1.39.0,>=1.38.16->boto3) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore<1.39.0,>=1.38.16->boto3) (2.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.39.0,>=1.38.16->boto3) (1.17.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install boto3\n",
        "!pip install tensorflow\n",
        "import copy\n",
        "import os\n",
        "import boto3\n",
        "import traceback\n",
        "import io\n",
        "import json\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from botocore.exceptions import ClientError, NoCredentialsError\n",
        "from traceback import format_exc\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "os.environ['AWS_ACCESS_KEY_ID'] = <access_key>\n",
        "os.environ['AWS_SECRET_ACCESS_KEY'] = <secret_access_key>\n",
        "\n",
        "BUCKET = 'russian-stocks-quotes'\n",
        "\n",
        "access_key = os.getenv('AWS_ACCESS_KEY_ID')\n",
        "secret_key = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
        "endpoint_url = 'https://storage.yandexcloud.net'\n",
        "\n",
        "# Создание клиента S3\n",
        "s3_client = boto3.client('s3',\n",
        "                         region_name='ru-central1',\n",
        "                         aws_access_key_id=access_key,\n",
        "                         aws_secret_access_key=secret_key,\n",
        "                         endpoint_url=endpoint_url)\n",
        "\n",
        "def download_object_from_s3(key):\n",
        "    response = s3_client.get_object(Bucket=BUCKET, Key=key)\n",
        "    if response['ResponseMetadata']['HTTPStatusCode'] == 200:\n",
        "        print(f\"Успешно получен из {BUCKET}/{key}\")\n",
        "    else:\n",
        "        print(f\"Ошибка при получении: {response['ResponseMetadata']['HTTPStatusCode']}\")\n",
        "    return response['Body'].read()\n",
        "\n",
        "def download_info_from_s3(dir, secid):\n",
        "    key = f'{dir}secids/{secid}/{secid}_info.pkl'\n",
        "    response = download_object_from_s3(key)\n",
        "    data = json.loads(response)\n",
        "    data['miss_index'] = pd.Index(np.array(data['miss_index']))\n",
        "    return data\n",
        "\n",
        "def download_data_frame_from_s3(dir, secid):\n",
        "    key = f'{dir}secids/{secid}/{secid}_data_frame.pkl'\n",
        "    response = download_object_from_s3(key)\n",
        "    buffer = io.BytesIO(response)\n",
        "    data = pd.read_pickle(buffer)\n",
        "    data['TRADEDATE'] = pd.to_datetime(data['TRADEDATE'])\n",
        "    return data\n",
        "\n",
        "def download_news_info_from_s3(dir, secid):\n",
        "    key = f'{dir}secids/{secid}/news_info.pkl'\n",
        "    response = download_object_from_s3(key)\n",
        "    return json.loads(response)\n",
        "\n",
        "def download_secid_names(dir):\n",
        "    key = f'{dir}secid_names.pkl'\n",
        "    return json.loads(download_object_from_s3(key))\n",
        "\n",
        "def fit_secids_from_s3(dir, secids=None):\n",
        "    data = {}\n",
        "    try:\n",
        "        directories = download_secid_names(dir)\n",
        "        for secid in directories:\n",
        "            if (secids is None or secid in secids) and secid >= 'AFLT':\n",
        "                if secids is not None:\n",
        "                    secids.remove(secid)\n",
        "                try:\n",
        "                    news_info = download_news_info_from_s3(dir, secid)\n",
        "                except Exception:\n",
        "                    news_info = {}\n",
        "                fit_secid(secid, download_data_frame_from_s3(dir, secid), news_info)\n",
        "    except Exception as e:\n",
        "        error_message = f\"Неизвестная ошибка: {str(e)}\"\n",
        "        error_context = traceback.format_exc()\n",
        "        print(f\"{error_message}\\nКонтекст ошибки:\\n{error_context}\")\n",
        "    if secids is not None and len(secids) > 0:\n",
        "        print(f'Не нашли {secids}')\n",
        "    return data\n",
        "\n",
        "def rmse(y_true, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "def mape(y_true, y_pred, epsilon=1e-6):\n",
        "    return np.mean(np.abs((y_true - y_pred) / (y_true + epsilon))) * 100\n",
        "\n",
        "def metrics(y_true, y_pred):\n",
        "  # корень из квадратичной ошибки, возвращает ошибку в тех же единицах, что и целевая переменная\n",
        "  rmse_score = rmse(y_true, y_pred)\n",
        "  # измеряет ошибку в процентах и позволяет легко интерпретировать результаты\n",
        "  mape_score = mape(y_true, y_pred)\n",
        "  return tuple([rmse_score, mape_score])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhFZNrB4HhNI",
        "outputId": "ae4b0eef-f62e-4cc3-d7a0-01e62d939c26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Успешно получен из russian-stocks-quotes/preprocessed_data/secid_names.pkl\n",
            "Успешно получен из russian-stocks-quotes/preprocessed_data/secids/AFLT/news_info.pkl\n",
            "Успешно получен из russian-stocks-quotes/preprocessed_data/secids/AFLT/AFLT_data_frame.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-44-9fa9f1b090fb>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  secid_data[column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  secid_data[column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  secid_data[column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  secid_data[column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:60: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.542' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  secid_data.at[index, column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:60: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.542' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  secid_data.at[index, column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:60: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.020294117647058796' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  secid_data.at[index, column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[lag_name] = secid_data['CLOSE'].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[lag_name] = secid_data['CLOSE'].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[lag_name] = secid_data['CLOSE'].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:127: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.60869565 0.60869565 0.60869565 ... 0.08695652 0.69565217 0.7826087 ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train.loc[:, valid_columns] = scaler.fit_transform(train[valid_columns])\n",
            "<ipython-input-44-9fa9f1b090fb>:127: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.         0.         0.         ... 0.20338983 0.88135593 0.20338983]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train.loc[:, valid_columns] = scaler.fit_transform(train[valid_columns])\n",
            "<ipython-input-44-9fa9f1b090fb>:127: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.60869565 0.60869565 0.60869565 ... 0.43478261 0.82608696 0.52173913]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train.loc[:, valid_columns] = scaler.fit_transform(train[valid_columns])\n",
            "<ipython-input-44-9fa9f1b090fb>:127: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.         0.         0.         ... 0.83050847 0.55932203 0.6779661 ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train.loc[:, valid_columns] = scaler.fit_transform(train[valid_columns])\n",
            "<ipython-input-44-9fa9f1b090fb>:127: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.         0.         0.         ... 0.43478261 0.39130435 0.33333333]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train.loc[:, valid_columns] = scaler.fit_transform(train[valid_columns])\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Обучение LSTM на AFLT\n",
            "1\n",
            "2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "37\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "74\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "407\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "814\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Успешно сохранен в russian-stocks-quotes/predictions/AFLT/lstm_with_news.pkl\n",
            "Успешно получен из russian-stocks-quotes/preprocessed_data/secids/AGRO/news_info.pkl\n",
            "Успешно получен из russian-stocks-quotes/preprocessed_data/secids/AGRO/AGRO_data_frame.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-44-9fa9f1b090fb>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  secid_data[column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  secid_data[column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  secid_data[column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  secid_data[column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:60: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.012' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  secid_data.at[index, column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:60: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.542' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  secid_data.at[index, column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:60: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.189' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  secid_data.at[index, column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[lag_name] = secid_data['CLOSE'].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[lag_name] = secid_data['CLOSE'].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[lag_name] = secid_data['CLOSE'].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:127: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.60869565 0.60869565 0.60869565 ... 0.69565217 0.69565217 0.39130435]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train.loc[:, valid_columns] = scaler.fit_transform(train[valid_columns])\n",
            "<ipython-input-44-9fa9f1b090fb>:127: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.         0.         0.         ... 0.23728814 0.94915254 0.42372881]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train.loc[:, valid_columns] = scaler.fit_transform(train[valid_columns])\n",
            "<ipython-input-44-9fa9f1b090fb>:127: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.57142857 0.57142857 0.57142857 ... 0.9047619  0.71428571 0.33333333]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train.loc[:, valid_columns] = scaler.fit_transform(train[valid_columns])\n",
            "<ipython-input-44-9fa9f1b090fb>:127: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.         0.         0.         ... 0.47457627 0.86440678 0.42372881]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train.loc[:, valid_columns] = scaler.fit_transform(train[valid_columns])\n",
            "<ipython-input-44-9fa9f1b090fb>:127: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.         0.         0.         ... 0.64285714 0.35714286 0.        ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train.loc[:, valid_columns] = scaler.fit_transform(train[valid_columns])\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Обучение LSTM на AGRO\n",
            "1\n",
            "2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "353\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Успешно сохранен в russian-stocks-quotes/predictions/AGRO/lstm_with_news.pkl\n",
            "Успешно получен из russian-stocks-quotes/preprocessed_data/secids/AKRN/news_info.pkl\n",
            "Успешно получен из russian-stocks-quotes/preprocessed_data/secids/AKRN/AKRN_data_frame.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-44-9fa9f1b090fb>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  secid_data[column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  secid_data[column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  secid_data[column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  secid_data[column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:60: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.007' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  secid_data.at[index, column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:60: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.007' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  secid_data.at[index, column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:60: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.007' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  secid_data.at[index, column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[lag_name] = secid_data['CLOSE'].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[lag_name] = secid_data['CLOSE'].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[lag_name] = secid_data['CLOSE'].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:127: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.55 0.55 0.55 ... 0.55 0.55 0.55]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train.loc[:, valid_columns] = scaler.fit_transform(train[valid_columns])\n",
            "<ipython-input-44-9fa9f1b090fb>:127: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0. 0. 0. ... 0. 0. 0.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train.loc[:, valid_columns] = scaler.fit_transform(train[valid_columns])\n",
            "<ipython-input-44-9fa9f1b090fb>:127: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.60869565 0.60869565 0.60869565 ... 0.60869565 0.60869565 0.60869565]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train.loc[:, valid_columns] = scaler.fit_transform(train[valid_columns])\n",
            "<ipython-input-44-9fa9f1b090fb>:127: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0. 0. 0. ... 0. 0. 0.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train.loc[:, valid_columns] = scaler.fit_transform(train[valid_columns])\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Обучение LSTM на AKRN\n",
            "1\n",
            "3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "503\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Успешно сохранен в russian-stocks-quotes/predictions/AKRN/lstm_with_news.pkl\n",
            "Успешно получен из russian-stocks-quotes/preprocessed_data/secids/ALRS/news_info.pkl\n",
            "Успешно получен из russian-stocks-quotes/preprocessed_data/secids/ALRS/ALRS_data_frame.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-44-9fa9f1b090fb>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  secid_data[column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  secid_data[column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  secid_data[column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  secid_data[column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:60: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.151' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  secid_data.at[index, column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:60: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.187' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  secid_data.at[index, column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:60: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.015411764705882354' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  secid_data.at[index, column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[lag_name] = secid_data['CLOSE'].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[lag_name] = secid_data['CLOSE'].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[lag_name] = secid_data['CLOSE'].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:127: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.60869565 0.60869565 0.60869565 ... 0.65217391 0.56521739 0.30434783]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train.loc[:, valid_columns] = scaler.fit_transform(train[valid_columns])\n",
            "<ipython-input-44-9fa9f1b090fb>:127: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.         0.         0.         ... 0.3559322  0.61016949 0.06779661]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train.loc[:, valid_columns] = scaler.fit_transform(train[valid_columns])\n",
            "<ipython-input-44-9fa9f1b090fb>:127: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.60869565 0.60869565 0.60869565 ... 0.39130435 0.56521739 0.69565217]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train.loc[:, valid_columns] = scaler.fit_transform(train[valid_columns])\n",
            "<ipython-input-44-9fa9f1b090fb>:127: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.         0.         0.         ... 0.         0.43103448 0.65517241]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train.loc[:, valid_columns] = scaler.fit_transform(train[valid_columns])\n",
            "<ipython-input-44-9fa9f1b090fb>:127: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.         0.         0.         ... 0.5        0.57692308 0.38461538]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train.loc[:, valid_columns] = scaler.fit_transform(train[valid_columns])\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Обучение LSTM на ALRS\n",
            "1\n",
            "2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "277\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "554\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "831\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Успешно сохранен в russian-stocks-quotes/predictions/ALRS/lstm_with_news.pkl\n",
            "Успешно получен из russian-stocks-quotes/preprocessed_data/secids/AMEZ/AMEZ_data_frame.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-44-9fa9f1b090fb>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  secid_data[column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  secid_data[column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  secid_data[column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  secid_data[column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[lag_name] = secid_data['CLOSE'].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[lag_name] = secid_data['CLOSE'].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[lag_name] = secid_data['CLOSE'].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Обучение LSTM на AMEZ\n",
            "1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "503\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Успешно сохранен в russian-stocks-quotes/predictions/AMEZ/lstm_with_news.pkl\n",
            "Успешно получен из russian-stocks-quotes/preprocessed_data/secids/APRI/news_info.pkl\n",
            "Успешно получен из russian-stocks-quotes/preprocessed_data/secids/APRI/APRI_data_frame.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-44-9fa9f1b090fb>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  secid_data[column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  secid_data[column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  secid_data[column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  secid_data[column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:60: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.005' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  secid_data.at[index, column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:60: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.005' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  secid_data.at[index, column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:60: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.005' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  secid_data.at[index, column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[lag_name] = secid_data['CLOSE'].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[lag_name] = secid_data['CLOSE'].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[lag_name] = secid_data['CLOSE'].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:127: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.42857143 0.42857143 0.42857143 0.42857143 0.42857143 0.42857143\n",
            " 0.42857143 0.42857143 0.42857143 0.42857143 0.42857143 0.42857143\n",
            " 0.42857143 0.42857143 0.28571429 0.42857143 0.42857143 0.42857143\n",
            " 0.42857143 0.42857143 0.42857143 0.42857143 1.         0.42857143\n",
            " 0.42857143 0.42857143 0.42857143 0.42857143 0.42857143 0.42857143\n",
            " 0.42857143 0.42857143 0.42857143 0.42857143 0.42857143 0.42857143\n",
            " 0.85714286 0.42857143 0.42857143 0.42857143 0.42857143 0.42857143\n",
            " 0.42857143 0.42857143 0.42857143 0.42857143 0.         0.42857143\n",
            " 0.42857143 0.42857143 1.        ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train.loc[:, valid_columns] = scaler.fit_transform(train[valid_columns])\n",
            "<ipython-input-44-9fa9f1b090fb>:127: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.25862069 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.13793103 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.18965517 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.20689655 0.\n",
            " 0.         0.         1.        ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train.loc[:, valid_columns] = scaler.fit_transform(train[valid_columns])\n",
            "<ipython-input-44-9fa9f1b090fb>:127: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.42857143 0.42857143 0.42857143 0.42857143 0.42857143 0.42857143\n",
            " 0.42857143 0.42857143 0.42857143 0.42857143 0.42857143 0.42857143\n",
            " 0.42857143 0.42857143 0.28571429 0.42857143 0.42857143 0.42857143\n",
            " 0.42857143 0.42857143 0.42857143 0.42857143 1.         0.42857143\n",
            " 0.42857143 0.42857143 0.42857143 0.42857143 0.42857143 0.42857143\n",
            " 0.42857143 0.42857143 0.42857143 0.42857143 0.42857143 0.42857143\n",
            " 0.85714286 0.42857143 0.42857143 0.42857143 0.42857143 0.42857143\n",
            " 0.42857143 0.42857143 0.42857143 0.42857143 0.         0.42857143\n",
            " 0.42857143 0.42857143 1.        ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train.loc[:, valid_columns] = scaler.fit_transform(train[valid_columns])\n",
            "<ipython-input-44-9fa9f1b090fb>:127: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.25862069 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.13793103 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.18965517 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.20689655 0.\n",
            " 0.         0.         1.        ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train.loc[:, valid_columns] = scaler.fit_transform(train[valid_columns])\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Обучение LSTM на APRI\n",
            "1\n",
            "3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Успешно сохранен в russian-stocks-quotes/predictions/APRI/lstm_with_news.pkl\n",
            "Успешно получен из russian-stocks-quotes/preprocessed_data/secids/APTK/news_info.pkl\n",
            "Успешно получен из russian-stocks-quotes/preprocessed_data/secids/APTK/APTK_data_frame.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-44-9fa9f1b090fb>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  secid_data[column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  secid_data[column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  secid_data[column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  secid_data[column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:60: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.012' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  secid_data.at[index, column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:60: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.012' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  secid_data.at[index, column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:60: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.012' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  secid_data.at[index, column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[lag_name] = secid_data['CLOSE'].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[lag_name] = secid_data['CLOSE'].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[lag_name] = secid_data['CLOSE'].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:127: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.57142857 0.57142857 0.57142857 ... 0.57142857 0.57142857 0.57142857]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train.loc[:, valid_columns] = scaler.fit_transform(train[valid_columns])\n",
            "<ipython-input-44-9fa9f1b090fb>:127: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0. 0. 0. ... 0. 0. 0.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train.loc[:, valid_columns] = scaler.fit_transform(train[valid_columns])\n",
            "<ipython-input-44-9fa9f1b090fb>:127: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.57142857 0.57142857 0.57142857 ... 0.57142857 0.57142857 0.57142857]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train.loc[:, valid_columns] = scaler.fit_transform(train[valid_columns])\n",
            "<ipython-input-44-9fa9f1b090fb>:127: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0. 0. 0. ... 0. 0. 0.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train.loc[:, valid_columns] = scaler.fit_transform(train[valid_columns])\n",
            "<ipython-input-44-9fa9f1b090fb>:127: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0. 0. 0. ... 0. 0. 0.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train.loc[:, valid_columns] = scaler.fit_transform(train[valid_columns])\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Обучение LSTM на APTK\n",
            "1\n",
            "3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "503\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Успешно сохранен в russian-stocks-quotes/predictions/APTK/lstm_with_news.pkl\n",
            "Успешно получен из russian-stocks-quotes/preprocessed_data/secids/AQUA/news_info.pkl\n",
            "Успешно получен из russian-stocks-quotes/preprocessed_data/secids/AQUA/AQUA_data_frame.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-44-9fa9f1b090fb>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  secid_data[column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  secid_data[column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  secid_data[column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  secid_data[column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:60: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.091' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  secid_data.at[index, column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:60: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.091' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  secid_data.at[index, column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:60: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.091' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  secid_data.at[index, column] = value\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[lag_name] = secid_data['CLOSE'].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[lag_name] = secid_data['CLOSE'].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[lag_name] = secid_data['CLOSE'].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
            "<ipython-input-44-9fa9f1b090fb>:127: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.60869565 0.60869565 0.60869565 ... 0.60869565 0.60869565 0.60869565]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train.loc[:, valid_columns] = scaler.fit_transform(train[valid_columns])\n",
            "<ipython-input-44-9fa9f1b090fb>:127: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0. 0. 0. ... 0. 0. 0.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train.loc[:, valid_columns] = scaler.fit_transform(train[valid_columns])\n",
            "<ipython-input-44-9fa9f1b090fb>:127: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.60869565 0.60869565 0.60869565 ... 0.60869565 0.60869565 0.60869565]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train.loc[:, valid_columns] = scaler.fit_transform(train[valid_columns])\n",
            "<ipython-input-44-9fa9f1b090fb>:127: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0. 0. 0. ... 0. 0. 0.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train.loc[:, valid_columns] = scaler.fit_transform(train[valid_columns])\n",
            "<ipython-input-44-9fa9f1b090fb>:127: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0. 0. 0. ... 0. 0. 0.]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train.loc[:, valid_columns] = scaler.fit_transform(train[valid_columns])\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Обучение LSTM на AQUA\n",
            "1\n",
            "7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import copy\n",
        "import datetime\n",
        "import pickle\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "from keras.losses import Huber, MeanSquaredError\n",
        "from keras.layers import LayerNormalization\n",
        "from keras.optimizers import AdamW\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import math\n",
        "\n",
        "def divisors(n):\n",
        "    divisors = list()\n",
        "    for i in range(1, n):\n",
        "        if n % i == 0:\n",
        "            divisors.append(i)\n",
        "    return divisors\n",
        "\n",
        "lags = { 1: 'lag_1', 2: 'lag_2', 3: 'lag_3', 4: 'lag_4', 5: 'lag_week', 10: 'lag_2_weeks',\n",
        "        21: 'lag_month', 62: 'lag_3_months', 124: 'lag_half_year', 247: 'lag_year',\n",
        "        371: 'lag_year_with_half', 495: 'lag_2_years', 742: 'lag_3_years' }\n",
        "rev_lags = { 'lag_1': 1, 'lag_2': 2, 'lag_3': 3, 'lag_4': 4, 'lag_week': 5, 'lag_2_weeks': 10,\n",
        "            'lag_month': 21, 'lag_3_months': 62, 'lag_half_year': 124, 'lag_year': 247,\n",
        "            'lag_year_with_half': 371, 'lag_2_years': 495, 'lag_3_years': 742 }\n",
        "\n",
        "def lr_scheduler(epoch, lr):\n",
        "    if epoch < 50:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr * 0.95\n",
        "\n",
        "def upload_models_data_to_s3(secid, model_name, body):\n",
        "    key = f'predictions/{secid}/{model_name}.pkl'\n",
        "    response = s3_client.put_object(Bucket=BUCKET, Key=key, Body=pickle.dumps(body))\n",
        "    if response['ResponseMetadata']['HTTPStatusCode'] == 200:\n",
        "        print(f\"Успешно сохранен в {BUCKET}/{key}\")\n",
        "    else:\n",
        "        print(f\"Ошибка при сохранении: {response['ResponseMetadata']['HTTPStatusCode']}\")\n",
        "\n",
        "def fit_secid(secid, data_frame, news_info):\n",
        "  random.seed(42)\n",
        "  # Получаем данные по бумаге и удаляем дату\n",
        "  secid_data = data_frame[['TRADEDATE', 'CLOSE']]\n",
        "\n",
        "  # довавляем новостные колонки\n",
        "  for column, value in { 'min_importance': 0, 'max_importance': 0, 'min_importance_hour': 14, 'min_importance_minute': 0, 'max_importance_hour': 14, 'max_importance_minute': 0, 'count_news': 1, 'mean_importance': 0 }.items():\n",
        "    secid_data[column] = value\n",
        "\n",
        "  for index, row in secid_data.iterrows():\n",
        "    trade_date = row['TRADEDATE'].date()\n",
        "    if str(trade_date) in news_info:\n",
        "        for column, value in news_info[str(trade_date)].items():\n",
        "            if str(column) != 'min_importance_time' and str(column) != 'max_importance_time':\n",
        "                secid_data.at[index, column] = value\n",
        "            else:\n",
        "                hour, minute = value.split(':')\n",
        "                secid_data.at[index, column.replace('time', 'hour')] = int(hour)\n",
        "                secid_data.at[index, column.replace('time', 'minute')] = int(minute)\n",
        "\n",
        "  subset = pd.to_datetime(secid_data['TRADEDATE'])\n",
        "  secid_data = secid_data.drop('TRADEDATE', axis=1)\n",
        "\n",
        "  # добавляем дату по отдельности\n",
        "  secid_data.loc[:, 'year'] = subset.dt.year\n",
        "  secid_data.loc[:, 'month'] = subset.dt.month\n",
        "  secid_data.loc[:, 'day'] = subset.dt.day\n",
        "\n",
        "  importance_columns = ['min_importance', 'max_importance', 'min_importance_hour', 'min_importance_minute', 'max_importance_hour', 'max_importance_minute', 'count_news', 'mean_importance']\n",
        "  # Добавляем отступы по возможным корреляциям (очень сложно выбрать нормальные отсутпы по причине того, что торги на бирже не нормированы, есть праздники, переносы, блокировки торгов, переезд компаний и другое)\n",
        "  # но в среднем интернет выдал 247 с хвостиком рабочих дней в году, что я уже пытался нормально разделить, например для месяца получается 21 торговый день, хоть дней примерно 30\n",
        "  for lag_name, lag_num in rev_lags.items():\n",
        "    secid_data[lag_name] = secid_data['CLOSE'].shift(lag_num)\n",
        "    for importance_column in importance_columns:\n",
        "        secid_data[f'{lag_name}_{importance_column}'] = secid_data[importance_column].shift(lag_num)\n",
        "\n",
        "  # Далее убираются строки по лагам, которые не имеют данных, если данных остается меньше чем на 3 месяца или меньше 10% от начальных данных, то удаляется полностью колонка\n",
        "  # Потому что может быть ситуация, что данных на 3 года и 2 месяца, и только 2 месяца будут иметь лаг в 3 года, а я не хочу удалять так много данных\n",
        "  # Если же данных достаточно, то это будет самый большой лаг и удаляются строки, в которых по этому лагу пропуски. И переназначаем индексы\n",
        "  # lags = ['lag_3_years', 'lag_2_years', 'lag_year_with_half', 'lag_year', 'lag_half_year', 'lag_3_months', 'lag_month', 'lag_2_weeks', 'lag_week', 'lag_4', 'lag_3', 'lag_2', 'lag_1']\n",
        "  lag_names = list(reversed(lags.values()))\n",
        "  for lag in lag_names:\n",
        "    if secid_data[lag].isnull().sum() > 0:\n",
        "      temp = secid_data.dropna(subset=[lag])\n",
        "      if len(temp) < 62 or len(temp) * 10 < len(secid_data):\n",
        "        secid_data = secid_data.drop(columns=[lag])\n",
        "        for importance_column in importance_columns:\n",
        "            secid_data = secid_data.drop(columns=[f'{lag}_{importance_column}'])\n",
        "      else:\n",
        "        secid_data = temp\n",
        "        break\n",
        "  secid_data = secid_data.reset_index().drop('index', axis=1)\n",
        "  if secid_data.shape[0] < 6:\n",
        "    return\n",
        "\n",
        "  for importance_column in importance_columns:\n",
        "    secid_data[f'next_{importance_column}'] = secid_data[importance_column].shift(-1)\n",
        "\n",
        "  secid_data = secid_data[:-1]\n",
        "\n",
        "  # Разбиваем данные, в валидацию идет 20%\n",
        "  train_size = int(len(secid_data) * 0.8)\n",
        "  train, test = secid_data[:train_size], secid_data[train_size:]\n",
        "\n",
        "  valid_columns = [column for column in list(reversed(lags.values())) if column in test.columns.tolist()]\n",
        "  valid_columns.append('CLOSE')\n",
        "  # Очищаем те данные, что в валидацию попали из валидационных данных (чтобы не пытаться использовать известные реальные целевые значения для обучения)\n",
        "  for lag_name, lag_num in rev_lags.items():\n",
        "    if lag_name in valid_columns:\n",
        "      test.loc[test[lag_name] == test['CLOSE'].shift(lag_num), lag_name] = np.nan\n",
        "      for importance_column in importance_columns:\n",
        "          test.loc[test[f'{lag_name}_{importance_column}'] == test[importance_column].shift(lag_num), f'{lag_name}_{importance_column}'] = np.nan\n",
        "\n",
        "  importance_data_cols = ['min_importance_hour', 'min_importance_minute', 'max_importance_hour', 'max_importance_minute', 'count_news']\n",
        "  for importance_column in importance_data_cols:\n",
        "    valid_columns.extend([f'{lag}_{importance_column}' for lag in rev_lags.keys() if lag in valid_columns])\n",
        "  valid_columns.extend(importance_data_cols)\n",
        "\n",
        "  # нормализуем лаги (не трогаем таргет и даты)\n",
        "  scaler = MinMaxScaler()\n",
        "  # valid_columns = ['lag_3_years', 'lag_2_years', 'lag_year_with_half', 'lag_year', 'lag_half_year', 'lag_3_months', 'lag_month', 'lag_2_weeks', 'lag_week', 'lag_4', 'lag_3', 'lag_2', 'lag_1', 'CLOSE']\n",
        "  train.loc[:, valid_columns] = scaler.fit_transform(train[valid_columns])\n",
        "  # val[valid_columns] = scaler.transform(val[valid_columns])\n",
        "\n",
        "  base_models = [\n",
        "      {\n",
        "          'name': 'lstm_with_news',\n",
        "          'model': 'LSTM',\n",
        "          'grid_params': {},\n",
        "          'importances_name': ''\n",
        "      }\n",
        "  ]\n",
        "  models_data = copy.deepcopy(base_models)\n",
        "  for data in models_data:\n",
        "    print(f\"Обучение {data['model']} на {secid}\")\n",
        "    train_data = copy.deepcopy(train)\n",
        "    test_data = copy.deepcopy(test)\n",
        "\n",
        "    target_columns = [f'next_{importance_column}' for importance_column in importance_columns] + ['CLOSE']\n",
        "    X_train = train_data.drop(target_columns, axis=1)\n",
        "    y_train = train_data[target_columns]\n",
        "\n",
        "    features = X_train.shape[1]\n",
        "    best_first_10_mape_sum = float('inf')\n",
        "    best_data = None\n",
        "    for timesteps in divisors(X_train.shape[0]):\n",
        "      metric_scores = list()\n",
        "      predictions = list()\n",
        "      print(timesteps)\n",
        "      X_train_reshaped = X_train.to_numpy().reshape((X_train.shape[0] // timesteps, timesteps, features))\n",
        "      # обучаем модель\n",
        "      model = Sequential()\n",
        "      model.add(LSTM(48, input_shape=(timesteps, features),\n",
        "                    return_sequences=True,\n",
        "                    kernel_initializer='he_normal',\n",
        "                    recurrent_dropout=0.1))\n",
        "      model.add(LayerNormalization())\n",
        "      model.add(Dropout(0.2))\n",
        "      model.add(LSTM(24, return_sequences=False))\n",
        "      model.add(LayerNormalization())\n",
        "      model.add(Dense(16, activation='relu'))\n",
        "      model.add(Dense(len(target_columns)))\n",
        "\n",
        "      optimizer = Adam(learning_rate=0.001, clipnorm=1.0)\n",
        "      model.compile(optimizer=optimizer, loss=Huber())\n",
        "\n",
        "      history = model.fit(\n",
        "        X_train_reshaped, y_train,\n",
        "        epochs=200,\n",
        "        verbose=0,\n",
        "        batch_size=32,\n",
        "        validation_split=0.2,\n",
        "        callbacks=[\n",
        "            EarlyStopping(patience=15, restore_best_weights=True),\n",
        "            LearningRateScheduler(lr_scheduler)\n",
        "        ]\n",
        "      )\n",
        "      for index, row in test_data.iterrows():\n",
        "        df = pd.DataFrame([row])\n",
        "        # т.к. все кроме первой строки будут иметь пропуски в лагах, то перед предсказанием устанавливается лаг равный -n предсказанию\n",
        "        for col in df.columns[df.isnull().any()].tolist():\n",
        "          for lag in reversed(rev_lags.keys()):\n",
        "            if col.startswith(lag):\n",
        "              if lag == col:\n",
        "                df[col] = predictions[-rev_lags[lag]][-1]\n",
        "              else:\n",
        "                for index in range(len(importance_columns)):\n",
        "                  if col.endswith(importance_columns[index]):\n",
        "                    df[col] = predictions[-rev_lags[lag]][index]\n",
        "              break\n",
        "        # и делается нормализация\n",
        "        df[valid_columns] = scaler.transform(df[valid_columns])\n",
        "        prediction = model.predict(df.drop(target_columns, axis=1).to_numpy().reshape((1, 1, features)), verbose=0)[0]\n",
        "        pred_df = copy.deepcopy(df)\n",
        "        pred_df[target_columns] = prediction[0]\n",
        "        # записываются ошибки и предсказание\n",
        "        df[valid_columns] = scaler.inverse_transform(df[valid_columns])\n",
        "        pred_df[valid_columns] = scaler.inverse_transform(pred_df[valid_columns])\n",
        "        prediction_metric = metrics(np.array([df['CLOSE']]), np.array([pred_df['CLOSE']]))\n",
        "        metric_scores.append({ 'rmse': prediction_metric[0], 'mape': prediction_metric[1] })\n",
        "        predictions.append(pred_df[target_columns].to_numpy()[0])\n",
        "      data['predictions'] = [prediction[-1] for prediction in predictions]\n",
        "      data['metric_scores'] = metric_scores\n",
        "      data['importances'] = np.array([])\n",
        "      data['time'] = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "      data['best_params'] = { 'timesteps': timesteps }\n",
        "      data['best_model'] = model\n",
        "      sum_first_10_mape = sum([metric_score['mape'] for metric_score in metric_scores][:10])\n",
        "      if sum_first_10_mape < best_first_10_mape_sum:\n",
        "        best_first_10_mape_sum = sum_first_10_mape\n",
        "        best_data = copy.deepcopy(data)\n",
        "    upload_models_data_to_s3(secid, best_data['name'], best_data)\n",
        "pred_df = None\n",
        "fit_secids_from_s3('preprocessed_data/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTEIdRPGhnV_",
        "outputId": "aafb9da3-12ca-4527-ff27-7c83cd919157"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Успешное получение в russian-stocks-quotes/predictions/ABIO/ridge.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator Ridge from version 1.4.1.post1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ridge 53.65024793546407\n",
            "Успешное получение в russian-stocks-quotes/predictions/ABIO/random_forest.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.4.1.post1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator RandomForestRegressor from version 1.4.1.post1 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "random_forest 90.89076449145021\n",
            "Успешное получение в russian-stocks-quotes/predictions/ABIO/xgboost.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [11:32:56] WARNING: /workspace/src/collective/../data/../common/error_msg.h:80: If you are loading a serialized model (like pickle in Python, RDS in R) or\n",
            "configuration generated by an older version of XGBoost, please export the model by calling\n",
            "`Booster.save_model` from that version first, then load it back in current version. See:\n",
            "\n",
            "    https://xgboost.readthedocs.io/en/stable/tutorials/saving_model.html\n",
            "\n",
            "for more details about differences between saving model and serializing.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "xgboost 98.11195043135926\n",
            "Успешное получение в russian-stocks-quotes/predictions/ABIO/lstm.pkl\n",
            "lstm 49.97989687159141\n",
            "Успешное получение в russian-stocks-quotes/predictions/ABIO/sarimax.pkl\n",
            "sarimax 350.28238343091783\n",
            "Успешное получение в russian-stocks-quotes/predictions/ABIO/ridge_with_news.pkl\n",
            "ridge_with_news 99.67151252161659\n",
            "Успешное получение в russian-stocks-quotes/predictions/ABIO/random_forest_with_news.pkl\n",
            "random_forest_with_news 68.48481481412664\n",
            "Успешное получение в russian-stocks-quotes/predictions/ABIO/xgboost_with_news.pkl\n",
            "xgboost_with_news 97.55654758711333\n",
            "Успешное получение в russian-stocks-quotes/predictions/ABIO/lstm_with_news.pkl\n",
            "lstm_with_news 116.91745502107239\n"
          ]
        }
      ],
      "source": [
        "# secid = 'ABIO'\n",
        "# def download_models_data_from_s3(secid, model_name):\n",
        "#     key = f'predictions/{secid}/{model_name}.pkl'\n",
        "#     response = s3_client.get_object(Bucket=BUCKET, Key=key)\n",
        "#     if response['ResponseMetadata']['HTTPStatusCode'] == 200:\n",
        "#         print(f\"Успешное получение в {BUCKET}/{key}\")\n",
        "#         return pickle.loads(response['Body'].read())\n",
        "#     else:\n",
        "#         print(f\"Ошибка при получение: {response['ResponseMetadata']['HTTPStatusCode']}\")\n",
        "\n",
        "# for model_name in ['ridge', 'random_forest', 'xgboost', 'lstm', 'sarimax', 'ridge_with_news', 'random_forest_with_news', 'xgboost_with_news', 'lstm_with_news']:\n",
        "#   fitted_model = download_models_data_from_s3(secid, model_name)\n",
        "#   # print(fitted_model)\n",
        "#   metric_scores = fitted_model['metric_scores']\n",
        "#   print(model_name, sum([metric_score['mape'] for metric_score in metric_scores][:10]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
